{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarforre/pomodoro-candle/blob/main/demo/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7XkUEma1e_B"
      },
      "source": [
        "# Structured Q&A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5_etrez1e_C"
      },
      "source": [
        "Source code: https://github.com/mozilla-ai/structured-qa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZy7fG9m1e_D"
      },
      "source": [
        "Docs: https://mozilla-ai.github.io/structured-qa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krGM9UfJ1e_D"
      },
      "source": [
        "## GPU Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovN0yrzD1e_D"
      },
      "source": [
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to `Edit`â†’`Notebook Settings`\n",
        "- Select T4 GPU from the Hardware Accelerator section\n",
        "- Click `Save` and accept.\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QT5YnqeT1e_D",
        "outputId": "1526b75e-dfb5-4745-8f1a-a854d2a64875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"GPU not available\")\n",
        "else:\n",
        "    print(\"GPU is available!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsS7VVy81e_E"
      },
      "source": [
        "## Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWSutevP1e_E"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet https://github.com/abetlen/llama-cpp-python/releases/download/v0.3.4-cu122/llama_cpp_python-0.3.4-cp311-cp311-linux_x86_64.whl\n",
        "%pip install --quiet structured-qa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47VXnu0F1e_E"
      },
      "source": [
        "## Uploading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zglp9edQ1e_E"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLqHInoq1e_E"
      },
      "source": [
        "## Converting document to a directory of sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwA0ujK11e_E"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from structured_qa.preprocessing import document_to_sections_dir\n",
        "\n",
        "input_file = list(uploaded.keys())[0]\n",
        "sections_dir = f\"output/{Path(input_file).stem}\"\n",
        "section_names = document_to_sections_dir(input_file, sections_dir)\n",
        "section_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYMFwgfA1e_E"
      },
      "source": [
        "## Loading model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uICClJxq1e_F"
      },
      "outputs": [],
      "source": [
        "from structured_qa.model_loaders import load_llama_cpp_model\n",
        "\n",
        "model = load_llama_cpp_model(\n",
        "    \"bartowski/Qwen2.5-7B-Instruct-GGUF/Qwen2.5-7B-Instruct-Q8_0.gguf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHmeHH9J1e_F"
      },
      "source": [
        "## Find, Retrieve, and Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc2J1ivt1e_F"
      },
      "outputs": [],
      "source": [
        "FIND_PROMPT = \"\"\"\n",
        "You are given two pieces of information:\n",
        "1. A list of valid section names.\n",
        "2. A user question.\n",
        "\n",
        "Your task is to:\n",
        "- Identify exactly one `section_name` from the provided list that seems related to the user question.\n",
        "- Return the `section_name` exactly as it appears in the list.\n",
        "- Do NOT answer the question.\n",
        "- Do NOT return any additional text, explanation, or formatting.\n",
        "- Do NOT combine multiple section names into a single response.\n",
        "\n",
        "Here is the list of valid section names:\n",
        "\n",
        "```\n",
        "{SECTIONS}\n",
        "```\n",
        "\n",
        "Now, based on the following question, return the single most relevant `section_name` from the list.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WGHHmCq1e_F"
      },
      "outputs": [],
      "source": [
        "ANSWER_PROMPT = \"\"\"\n",
        "You are a rigorous assistant answering questions.\n",
        "You must only answer based on the current information available which is:\n",
        "\n",
        "```\n",
        "{CURRENT_INFO}\n",
        "```\n",
        "\n",
        "If the current information available not enough to answer the question,\n",
        "you must return \"I need more info\" and nothing else.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGQLgsrh1e_F"
      },
      "outputs": [],
      "source": [
        "QUESTION = \"What optimizer was used to train the model?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvKt56N01e_F"
      },
      "outputs": [],
      "source": [
        "from structured_qa.workflow import find_retrieve_answer\n",
        "\n",
        "find_retrieve_answer(\n",
        "    question=QUESTION,\n",
        "    model=model,\n",
        "    sections_dir=sections_dir,\n",
        "    find_prompt=FIND_PROMPT,\n",
        "    answer_prompt=ANSWER_PROMPT,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LIpNMpU1e_F"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}